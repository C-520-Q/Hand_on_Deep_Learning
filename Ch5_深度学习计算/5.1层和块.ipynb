{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T15:22:03.777630600Z",
     "start_time": "2024-10-15T15:22:01.561023600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0241, -0.3848, -0.6349,  0.0947,  0.0906, -0.1199, -0.3115,  0.3495,\n         -0.1794,  0.1520],\n        [-0.0744,  0.2651, -0.4299, -0.0009,  0.0577, -0.0889,  0.0272,  0.0768,\n          0.1308, -0.0941]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net=nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "\n",
    "X=torch.randn(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1.1自定义块"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b30de55ad65a2fac"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-9.0282e-02,  8.3717e-01,  9.7856e-02,  1.2094e-01,  1.0872e-01,\n         -1.7735e-01,  4.6022e-02,  1.6405e-01, -3.8527e-01, -2.8815e-01],\n        [ 9.1108e-03,  5.7216e-01,  1.0787e-02,  4.5813e-04,  3.1982e-01,\n         -5.2695e-02, -6.8458e-03, -9.8541e-03, -4.5075e-01, -6.7615e-01]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层这里，声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化\n",
    "        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params\n",
    "        super().__init__()\n",
    "        self.hidden=nn.Linear(20,256)   # 隐藏层\n",
    "        self.out=nn.Linear(256,10)    # 输出层\n",
    "    # 定义函数的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self,X):\n",
    "        # 注意，这里使用ReLu的函数版本，其在nn.functional模块中定义\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "    \n",
    "net=MLP()\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T15:22:03.796861700Z",
     "start_time": "2024-10-15T15:22:03.772886300Z"
    }
   },
   "id": "7813156652d19e0c",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1.2顺序块"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7310793891d141a1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0138, -0.2686,  0.1673, -0.3724, -0.0462, -0.3816,  0.1561,  0.1268,\n          0.3489,  0.1255],\n        [-0.0246, -0.6716, -0.1847,  0.0671, -0.0239, -0.1628, -0.2983,  0.3357,\n          0.1598, -0.1904]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self,*args):\n",
    "        super().__init__()\n",
    "        for idx,module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例我们把它保存在Module类的成员\n",
    "            # 变量_modules中。_module的类型是OrderedDict\n",
    "            self._modules[str(idx)]=module\n",
    "    def forward(self,X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X=block(X)\n",
    "        return X\n",
    "    \n",
    "net=MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T15:24:56.247334800Z",
     "start_time": "2024-10-15T15:24:56.228864200Z"
    }
   },
   "id": "54f901edfb46f0fb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1.3在前向传播函数中执行代码"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86227a3c47cdbda3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1226, grad_fn=<SumBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数，因此其在训练期间保持不变\n",
    "        self.rand_weight=torch.randn((20,20),requires_grad=False)\n",
    "        self.linear=nn.Linear(20,20)\n",
    "    def forward(self,X):\n",
    "        X=self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X=F.relu(torch.mm(X,self.rand_weight)+1)\n",
    "        # 复用全连接层这相当于两个全连接层共享参数\n",
    "        X=self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() >1:\n",
    "            X/=2\n",
    "        return X.sum()\n",
    "    \n",
    "net=FixedHiddenMLP()\n",
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T15:44:48.618011100Z",
     "start_time": "2024-10-15T15:44:48.594090700Z"
    }
   },
   "id": "372193bc53d6ed72",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0967, grad_fn=<SumBackward0>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(nn.Linear(20,64),nn.ReLU(),\n",
    "                               nn.Linear(64,32),nn.ReLU())\n",
    "        self.linear=nn.Linear(32,16)\n",
    "    def forward(self,X):\n",
    "        return self.linear(self.net(X))\n",
    "    \n",
    "chimera=nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
    "chimera(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T15:47:27.176312600Z",
     "start_time": "2024-10-15T15:47:27.130992600Z"
    }
   },
   "id": "475b9d89f159e9e6",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
